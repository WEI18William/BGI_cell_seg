<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>cellbin.image.augmentation API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cellbin.image.augmentation</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import copy
import numpy as np
from skimage.exposure import equalize_adapthist
from skimage.exposure import rescale_intensity
from PIL import Image
import cv2
from numba import njit,prange
import math

from cellbin.modules import StainType


def f_rgb2gray(img, need_not=False):
    &#34;&#34;&#34;
    rgb2gray

    :param img: (CHANGE) np.array
    :param need_not: if need bitwise_not
    :return: np.array
    &#34;&#34;&#34;
    if img.ndim == 3:
        if img.shape[0] == 3 and img.shape[1] &gt; 3 and img.shape[2] &gt; 3:
            img = img.transpose(1, 2, 0)
        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        if need_not:
            img = cv2.bitwise_not(img)
    return img


def f_gray2bgr(img):
    &#34;&#34;&#34;
    gray2bgr

    :param img: (CHANGE) np.array
    :return: np.array
    &#34;&#34;&#34;

    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    return img


def f_padding(img, top, bot, left, right, mode=&#39;constant&#39;, value=0):
    &#34;&#34;&#34;
    update by dengzhonghan on 2023/2/23
    1. support 3d array padding.
    2. not support 1d array padding.

    Args:
        img (): numpy ndarray (2D or 3D).
        top (): number of values padded to the top direction.
        bot (): number of values padded to the bottom direction.
        left (): number of values padded to the left direction.
        right (): number of values padded to the right direction.
        mode (): padding mode in numpy, default is constant.
        value (): constant value when using constant mode, default is 0.

    Returns:
        pad_img: padded image.

    &#34;&#34;&#34;

    if mode == &#39;constant&#39;:
        if img.ndim == 2:
            pad_img = np.pad(img, ((top, bot), (left, right)), mode, constant_values=value)
        elif img.ndim == 3:
            pad_img = np.pad(img, ((top, bot), (left, right), (0, 0)), mode, constant_values=value)
    else:
        if img.ndim == 2:
            pad_img = np.pad(img, ((top, bot), (left, right)), mode)
        elif img.ndim == 3:
            pad_img = np.pad(img, ((top, bot), (left, right), (0, 0)), mode)
    return pad_img


def f_resize(img, shape=(1024, 2048), mode=&#34;NEAREST&#34;):
    &#34;&#34;&#34;
    resize img with pillow

    :param img: (CHANGE) np.array
    :param shape: tuple
    :param mode: An optional resampling filter. This can be one of Resampling.NEAREST,
     Resampling.BOX, Resampling.BILINEAR, Resampling.HAMMING, Resampling.BICUBIC or Resampling.LANCZOS.
     If the image has mode “1” or “P”, it is always set to Resampling.NEAREST.
     If the image mode specifies a number of bits, such as “I;16”, then the default filter is Resampling.NEAREST.
     Otherwise, the default filter is Resampling.BICUBIC
    :return:np.array
    &#34;&#34;&#34;
    imode = Image.NEAREST
    if mode == &#34;BILINEAR&#34;:
        imode = Image.BILINEAR
    elif mode == &#34;BICUBIC&#34;:
        imode = Image.BICUBIC
    elif mode == &#34;LANCZOS&#34;:
        imode = Image.LANCZOS
    elif mode == &#34;HAMMING&#34;:
        imode = Image.HAMMING
    elif mode == &#34;BOX&#34;:
        imode = Image.BOX
    if img.dtype != &#39;uint8&#39;:
        imode = Image.NEAREST
    img = Image.fromarray(img)
    img = img.resize((shape[1], shape[0]), resample=imode)
    img = np.array(img).astype(np.uint8)
    return img


def f_percentile_threshold(img, percentile=99.9):
    &#34;&#34;&#34;
    Threshold an image to reduce bright spots

    :param img: (CHANGE) numpy array of image data
    :param percentile: cutoff used to threshold image
    :return: np.array: thresholded version of input image

    2023/09/20 @fxzhao 增加overwrite_input参数,可省去percentile的临时内存开销
    &#34;&#34;&#34;
    
    # non_zero_vals = img[np.nonzero(img)]
    non_zero_vals = img[img &gt; 0]

    # only threshold if channel isn&#39;t blank
    if len(non_zero_vals) &gt; 0:
        img_max = np.percentile(non_zero_vals, percentile, overwrite_input=True)

        # threshold values down to max
        threshold_mask = img &gt; img_max
        img[threshold_mask] = img_max

    return img


def f_equalize_adapthist(img, kernel_size=None):
    &#34;&#34;&#34;
    Pre-process images using Contrast Limited Adaptive
    Histogram Equalization (CLAHE).

    :param img: (CHANGE) (numpy.array): numpy array of phase image data.
    :param kernel_size: (integer): Size of kernel for CLAHE,
            defaults to 1/8 of image size.
    :return: numpy.array:Pre-processed image

    2023/09/20 @fxzhao 使用cv方法替换skimage方法,提高计算速度并降低内存占用
    &#34;&#34;&#34;
    # return equalize_adapthist(img, kernel_size=kernel_size)
    if kernel_size is None:
        kernel_size = 128
    clahe = cv2.createCLAHE(clipLimit=2.56, tileGridSize=(math.ceil(img.shape[0]/kernel_size),
                                                          math.ceil(img.shape[1]/kernel_size)))
    img = clahe.apply(img)
    return img


@njit(parallel=True)
def rescale_intensity_v2(img, out_range):
    imin = np.min(img)
    imax = np.max(img)
    _, omax = out_range

    for i in prange(img.shape[0]):
        for j in range(img.shape[1]):
            img[i][j] = ((img[i][j]-imin)/(imax-imin))*omax
    return img

def f_histogram_normalization(img):
    &#34;&#34;&#34;
    If one of the inputs is a constant-value array, it will
    be normalized as an array of all zeros of the same shape.

    :param img: (CHANGE) (numpy.array): numpy array of phase image data.
    :return: numpy.array:image data with dtype float32.

    2023/09/20 @fxzhao 使用numba加速rescale_intensity方法
    &#34;&#34;&#34;

    img = img.astype(&#39;float32&#39;)
    sample_value = img[(0,) * img.ndim]
    if (img == sample_value).all():
        return np.zeros_like(img)
    # img = rescale_intensity(img, out_range=(0.0, 1.0))
    img = rescale_intensity_v2(img, out_range=(0.0, 1.0))
    return img


def f_ij_16_to_8(img, chunk_size=1000):
    &#34;&#34;&#34;
    16 bits img to 8 bits

    :param img: (CHANGE) np.array
    :param chunk_size: chunk size (bit)
    :return: np.array
    &#34;&#34;&#34;

    if img.dtype == &#39;uint8&#39;:
        return img
    dst = np.zeros(img.shape, np.uint8)
    p_max = np.max(img)
    p_min = np.min(img)
    scale = 256.0 / (p_max - p_min + 1)
    for idx in range(img.shape[0] // chunk_size + 1):
        sl = slice(idx * chunk_size, (idx + 1) * chunk_size)
        win_img = copy.deepcopy(img[sl])
        win_img = np.int16(win_img)
        win_img = (win_img &amp; 0xffff)
        win_img = win_img - p_min
        win_img[win_img &lt; 0] = 0
        win_img = win_img * scale + 0.5
        win_img[win_img &gt; 255] = 255
        dst[sl] = np.array(win_img).astype(np.uint8)
    return dst

@njit(parallel=True)
def f_ij_16_to_8_v2(img):
    &#34;&#34;&#34;
    2023/09/20 @fxzhao f_ij_16_to_8的升级版本,使用numba加速
    &#34;&#34;&#34;
    dst = np.zeros(img.shape, np.uint8)
    p_max = np.max(img)
    p_min = np.min(img)
    scale = 256.0 / (p_max - p_min + 1)
    for i in prange(img.shape[0]):
        for j in range(img.shape[1]):
            v = img[i][j]
            v = np.int16(v)
            v = (v &amp; 0xffff)
            v = v - p_min
            v = max(v, 0)
            v = v * scale + 0.5
            v = np.uint8(min(v, 255))
            dst[i][j] = v
    return dst

def enhance(arr, mode, thresh):
    &#34;&#34;&#34;
    Only support 2D array

    Args:
        arr (): 2D numpy array
        mode (): enhance mode
        thresh (): threshold

    Returns:

    &#34;&#34;&#34;
    data = arr.ravel()
    min_v = np.min(data)
    data_ = data[np.where(data &lt;= thresh)]
    if len(data_) == 0:
        return 0, 0
    if mode == &#39;median&#39;:
        var_ = np.std(data_)
        thr = np.median(data_)
        max_v = thr + var_
    elif mode == &#39;hist&#39;:
        freq_count, bins = np.histogram(data_, range(min_v, int(thresh + 1)))
        count = np.sum(freq_count)
        freq = freq_count / count
        thr = bins[np.argmax(freq)]
        max_v = thr + (thr - min_v)
    else:
        raise Exception(&#39;Only support median and histogram&#39;)

    return min_v, max_v


def encode(arr, min_v, max_v):
    &#34;&#34;&#34;
    Encode image with min and max pixel value

    Args:
        arr (): 2D numpy array
        min_v (): min value obtained from enhance method
        max_v (): max value

    Returns:
        mat: encoded mat

    &#34;&#34;&#34;
    if min_v &gt;= max_v:
        arr = arr.astype(np.uint8)
        return arr
    mat = np.zeros((arr.shape[0], arr.shape[1]), dtype=np.uint8)
    v_w = max_v - min_v
    mat[arr &lt; min_v] = 0
    mat[arr &gt; max_v] = 255
    pos = (arr &gt;= min_v) &amp; (arr &lt;= max_v)
    mat[pos] = (arr[pos] - min_v) * (255 / v_w)
    return mat


def f_ij_auto_contrast(img):
    &#34;&#34;&#34;
        auto contrast from imagej
        Args:
            img(ndarray): img array

        Returns(ndarray):img array

        &#34;&#34;&#34;
    limit = img.size / 10
    threshold = img.size / 5000
    if img.dtype != &#39;uint8&#39;:
        bit_max = 65536
    else:
        bit_max = 256
    hist, _ = np.histogram(img.flatten(), 256, [0, bit_max])
    hmin = 0
    hmax = bit_max - 1
    for i in range(1, len(hist) - 1):
        count = hist[i]
        if count &gt; limit:
            continue
        if count &gt; threshold:
            hmin = i
            break
    for i in range(len(hist) - 2, 0, -1):
        count = hist[i]
        if count &gt; limit:
            continue
        if count &gt; threshold:
            hmax = i
            break
    if hmax &gt; hmin:
        hmax = int(hmax * bit_max / 256)
        hmin = int(hmin * bit_max / 256)
        img[img &lt; hmin] = hmin
        img[img &gt; hmax] = hmax
        cv2.normalize(img, img, 0, bit_max - 1, cv2.NORM_MINMAX)
    return img


def dapi_enhance(img_obj):
    &#34;&#34;&#34;
    if you implement a new enhance method, the returned arr must be in bgr format

    Args:
        img_obj ():

    Returns:
        bgr_arr: numpy array in bgr format

    &#34;&#34;&#34;
    depth = img_obj.depth
    th = int((1 &lt;&lt; depth) * (1 - 0.618))
    arr = img_obj.image  # 2d array
    min_v, max_v = enhance(arr, mode=&#39;hist&#39;, thresh=th)
    enhance_arr = encode(arr, min_v, max_v)  # 2d array
    bgr_arr = f_gray2bgr(enhance_arr)  # 3d array in bgr format
    return bgr_arr


def he_enhance(img_obj):
    &#34;&#34;&#34;
    add by @limin on 2023/05/15

    &#34;&#34;&#34;
    arr = img_obj.image
    if arr.ndim == 3:
        arr = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)  # todo: rgb or bgr
    if arr.dtype == &#39;uint16&#39;:
        arr = cv2.normalize(arr, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    MAX_RANGE = np.power(2, 8)
    arr_invert = (MAX_RANGE - arr).astype(np.uint8)
    arr_invert = cv2.equalizeHist(arr_invert)
    bgr_arr = f_gray2bgr(arr_invert)  # 3d array in bgr format
    return bgr_arr


pt_enhance_method = {
    StainType.ssDNA.value: dapi_enhance,
    StainType.DAPI.value: dapi_enhance,
    StainType.HE.value: he_enhance
}

line_enhance_method = {
    StainType.HE.value: he_enhance
}

clarity_enhance_method = {
    StainType.HE.value: f_rgb2gray
}</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cellbin.image.augmentation.dapi_enhance"><code class="name flex">
<span>def <span class="ident">dapi_enhance</span></span>(<span>img_obj)</span>
</code></dt>
<dd>
<div class="desc"><p>if you implement a new enhance method, the returned arr must be in bgr format</p>
<h2 id="args">Args</h2>
<p>img_obj ():</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bgr_arr</code></dt>
<dd>numpy array in bgr format</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dapi_enhance(img_obj):
    &#34;&#34;&#34;
    if you implement a new enhance method, the returned arr must be in bgr format

    Args:
        img_obj ():

    Returns:
        bgr_arr: numpy array in bgr format

    &#34;&#34;&#34;
    depth = img_obj.depth
    th = int((1 &lt;&lt; depth) * (1 - 0.618))
    arr = img_obj.image  # 2d array
    min_v, max_v = enhance(arr, mode=&#39;hist&#39;, thresh=th)
    enhance_arr = encode(arr, min_v, max_v)  # 2d array
    bgr_arr = f_gray2bgr(enhance_arr)  # 3d array in bgr format
    return bgr_arr</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.encode"><code class="name flex">
<span>def <span class="ident">encode</span></span>(<span>arr, min_v, max_v)</span>
</code></dt>
<dd>
<div class="desc"><p>Encode image with min and max pixel value</p>
<h2 id="args">Args</h2>
<p>arr (): 2D numpy array
min_v (): min value obtained from enhance method
max_v (): max value</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mat</code></dt>
<dd>encoded mat</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def encode(arr, min_v, max_v):
    &#34;&#34;&#34;
    Encode image with min and max pixel value

    Args:
        arr (): 2D numpy array
        min_v (): min value obtained from enhance method
        max_v (): max value

    Returns:
        mat: encoded mat

    &#34;&#34;&#34;
    if min_v &gt;= max_v:
        arr = arr.astype(np.uint8)
        return arr
    mat = np.zeros((arr.shape[0], arr.shape[1]), dtype=np.uint8)
    v_w = max_v - min_v
    mat[arr &lt; min_v] = 0
    mat[arr &gt; max_v] = 255
    pos = (arr &gt;= min_v) &amp; (arr &lt;= max_v)
    mat[pos] = (arr[pos] - min_v) * (255 / v_w)
    return mat</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.enhance"><code class="name flex">
<span>def <span class="ident">enhance</span></span>(<span>arr, mode, thresh)</span>
</code></dt>
<dd>
<div class="desc"><p>Only support 2D array</p>
<h2 id="args">Args</h2>
<p>arr (): 2D numpy array
mode (): enhance mode
thresh (): threshold
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enhance(arr, mode, thresh):
    &#34;&#34;&#34;
    Only support 2D array

    Args:
        arr (): 2D numpy array
        mode (): enhance mode
        thresh (): threshold

    Returns:

    &#34;&#34;&#34;
    data = arr.ravel()
    min_v = np.min(data)
    data_ = data[np.where(data &lt;= thresh)]
    if len(data_) == 0:
        return 0, 0
    if mode == &#39;median&#39;:
        var_ = np.std(data_)
        thr = np.median(data_)
        max_v = thr + var_
    elif mode == &#39;hist&#39;:
        freq_count, bins = np.histogram(data_, range(min_v, int(thresh + 1)))
        count = np.sum(freq_count)
        freq = freq_count / count
        thr = bins[np.argmax(freq)]
        max_v = thr + (thr - min_v)
    else:
        raise Exception(&#39;Only support median and histogram&#39;)

    return min_v, max_v</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_equalize_adapthist"><code class="name flex">
<span>def <span class="ident">f_equalize_adapthist</span></span>(<span>img, kernel_size=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Pre-process images using Contrast Limited Adaptive
Histogram Equalization (CLAHE).</p>
<p>:param img: (CHANGE) (numpy.array): numpy array of phase image data.
:param kernel_size: (integer): Size of kernel for CLAHE,
defaults to 1/8 of image size.
:return: numpy.array:Pre-processed image</p>
<p>2023/09/20 @fxzhao 使用cv方法替换skimage方法,提高计算速度并降低内存占用</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_equalize_adapthist(img, kernel_size=None):
    &#34;&#34;&#34;
    Pre-process images using Contrast Limited Adaptive
    Histogram Equalization (CLAHE).

    :param img: (CHANGE) (numpy.array): numpy array of phase image data.
    :param kernel_size: (integer): Size of kernel for CLAHE,
            defaults to 1/8 of image size.
    :return: numpy.array:Pre-processed image

    2023/09/20 @fxzhao 使用cv方法替换skimage方法,提高计算速度并降低内存占用
    &#34;&#34;&#34;
    # return equalize_adapthist(img, kernel_size=kernel_size)
    if kernel_size is None:
        kernel_size = 128
    clahe = cv2.createCLAHE(clipLimit=2.56, tileGridSize=(math.ceil(img.shape[0]/kernel_size),
                                                          math.ceil(img.shape[1]/kernel_size)))
    img = clahe.apply(img)
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_gray2bgr"><code class="name flex">
<span>def <span class="ident">f_gray2bgr</span></span>(<span>img)</span>
</code></dt>
<dd>
<div class="desc"><p>gray2bgr</p>
<p>:param img: (CHANGE) np.array
:return: np.array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_gray2bgr(img):
    &#34;&#34;&#34;
    gray2bgr

    :param img: (CHANGE) np.array
    :return: np.array
    &#34;&#34;&#34;

    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_histogram_normalization"><code class="name flex">
<span>def <span class="ident">f_histogram_normalization</span></span>(<span>img)</span>
</code></dt>
<dd>
<div class="desc"><p>If one of the inputs is a constant-value array, it will
be normalized as an array of all zeros of the same shape.</p>
<p>:param img: (CHANGE) (numpy.array): numpy array of phase image data.
:return: numpy.array:image data with dtype float32.</p>
<p>2023/09/20 @fxzhao 使用numba加速rescale_intensity方法</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_histogram_normalization(img):
    &#34;&#34;&#34;
    If one of the inputs is a constant-value array, it will
    be normalized as an array of all zeros of the same shape.

    :param img: (CHANGE) (numpy.array): numpy array of phase image data.
    :return: numpy.array:image data with dtype float32.

    2023/09/20 @fxzhao 使用numba加速rescale_intensity方法
    &#34;&#34;&#34;

    img = img.astype(&#39;float32&#39;)
    sample_value = img[(0,) * img.ndim]
    if (img == sample_value).all():
        return np.zeros_like(img)
    # img = rescale_intensity(img, out_range=(0.0, 1.0))
    img = rescale_intensity_v2(img, out_range=(0.0, 1.0))
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_ij_16_to_8"><code class="name flex">
<span>def <span class="ident">f_ij_16_to_8</span></span>(<span>img, chunk_size=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>16 bits img to 8 bits</p>
<p>:param img: (CHANGE) np.array
:param chunk_size: chunk size (bit)
:return: np.array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_ij_16_to_8(img, chunk_size=1000):
    &#34;&#34;&#34;
    16 bits img to 8 bits

    :param img: (CHANGE) np.array
    :param chunk_size: chunk size (bit)
    :return: np.array
    &#34;&#34;&#34;

    if img.dtype == &#39;uint8&#39;:
        return img
    dst = np.zeros(img.shape, np.uint8)
    p_max = np.max(img)
    p_min = np.min(img)
    scale = 256.0 / (p_max - p_min + 1)
    for idx in range(img.shape[0] // chunk_size + 1):
        sl = slice(idx * chunk_size, (idx + 1) * chunk_size)
        win_img = copy.deepcopy(img[sl])
        win_img = np.int16(win_img)
        win_img = (win_img &amp; 0xffff)
        win_img = win_img - p_min
        win_img[win_img &lt; 0] = 0
        win_img = win_img * scale + 0.5
        win_img[win_img &gt; 255] = 255
        dst[sl] = np.array(win_img).astype(np.uint8)
    return dst</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_ij_16_to_8_v2"><code class="name flex">
<span>def <span class="ident">f_ij_16_to_8_v2</span></span>(<span>img)</span>
</code></dt>
<dd>
<div class="desc"><p>2023/09/20 @fxzhao f_ij_16_to_8的升级版本,使用numba加速</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(parallel=True)
def f_ij_16_to_8_v2(img):
    &#34;&#34;&#34;
    2023/09/20 @fxzhao f_ij_16_to_8的升级版本,使用numba加速
    &#34;&#34;&#34;
    dst = np.zeros(img.shape, np.uint8)
    p_max = np.max(img)
    p_min = np.min(img)
    scale = 256.0 / (p_max - p_min + 1)
    for i in prange(img.shape[0]):
        for j in range(img.shape[1]):
            v = img[i][j]
            v = np.int16(v)
            v = (v &amp; 0xffff)
            v = v - p_min
            v = max(v, 0)
            v = v * scale + 0.5
            v = np.uint8(min(v, 255))
            dst[i][j] = v
    return dst</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_ij_auto_contrast"><code class="name flex">
<span>def <span class="ident">f_ij_auto_contrast</span></span>(<span>img)</span>
</code></dt>
<dd>
<div class="desc"><p>auto contrast from imagej</p>
<h2 id="args">Args</h2>
<p>img(ndarray): img array
Returns(ndarray):img array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_ij_auto_contrast(img):
    &#34;&#34;&#34;
        auto contrast from imagej
        Args:
            img(ndarray): img array

        Returns(ndarray):img array

        &#34;&#34;&#34;
    limit = img.size / 10
    threshold = img.size / 5000
    if img.dtype != &#39;uint8&#39;:
        bit_max = 65536
    else:
        bit_max = 256
    hist, _ = np.histogram(img.flatten(), 256, [0, bit_max])
    hmin = 0
    hmax = bit_max - 1
    for i in range(1, len(hist) - 1):
        count = hist[i]
        if count &gt; limit:
            continue
        if count &gt; threshold:
            hmin = i
            break
    for i in range(len(hist) - 2, 0, -1):
        count = hist[i]
        if count &gt; limit:
            continue
        if count &gt; threshold:
            hmax = i
            break
    if hmax &gt; hmin:
        hmax = int(hmax * bit_max / 256)
        hmin = int(hmin * bit_max / 256)
        img[img &lt; hmin] = hmin
        img[img &gt; hmax] = hmax
        cv2.normalize(img, img, 0, bit_max - 1, cv2.NORM_MINMAX)
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_padding"><code class="name flex">
<span>def <span class="ident">f_padding</span></span>(<span>img, top, bot, left, right, mode='constant', value=0)</span>
</code></dt>
<dd>
<div class="desc"><p>update by dengzhonghan on 2023/2/23
1. support 3d array padding.
2. not support 1d array padding.</p>
<h2 id="args">Args</h2>
<p>img (): numpy ndarray (2D or 3D).
top (): number of values padded to the top direction.
bot (): number of values padded to the bottom direction.
left (): number of values padded to the left direction.
right (): number of values padded to the right direction.
mode (): padding mode in numpy, default is constant.
value (): constant value when using constant mode, default is 0.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pad_img</code></dt>
<dd>padded image.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_padding(img, top, bot, left, right, mode=&#39;constant&#39;, value=0):
    &#34;&#34;&#34;
    update by dengzhonghan on 2023/2/23
    1. support 3d array padding.
    2. not support 1d array padding.

    Args:
        img (): numpy ndarray (2D or 3D).
        top (): number of values padded to the top direction.
        bot (): number of values padded to the bottom direction.
        left (): number of values padded to the left direction.
        right (): number of values padded to the right direction.
        mode (): padding mode in numpy, default is constant.
        value (): constant value when using constant mode, default is 0.

    Returns:
        pad_img: padded image.

    &#34;&#34;&#34;

    if mode == &#39;constant&#39;:
        if img.ndim == 2:
            pad_img = np.pad(img, ((top, bot), (left, right)), mode, constant_values=value)
        elif img.ndim == 3:
            pad_img = np.pad(img, ((top, bot), (left, right), (0, 0)), mode, constant_values=value)
    else:
        if img.ndim == 2:
            pad_img = np.pad(img, ((top, bot), (left, right)), mode)
        elif img.ndim == 3:
            pad_img = np.pad(img, ((top, bot), (left, right), (0, 0)), mode)
    return pad_img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_percentile_threshold"><code class="name flex">
<span>def <span class="ident">f_percentile_threshold</span></span>(<span>img, percentile=99.9)</span>
</code></dt>
<dd>
<div class="desc"><p>Threshold an image to reduce bright spots</p>
<p>:param img: (CHANGE) numpy array of image data
:param percentile: cutoff used to threshold image
:return: np.array: thresholded version of input image</p>
<p>2023/09/20 @fxzhao 增加overwrite_input参数,可省去percentile的临时内存开销</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_percentile_threshold(img, percentile=99.9):
    &#34;&#34;&#34;
    Threshold an image to reduce bright spots

    :param img: (CHANGE) numpy array of image data
    :param percentile: cutoff used to threshold image
    :return: np.array: thresholded version of input image

    2023/09/20 @fxzhao 增加overwrite_input参数,可省去percentile的临时内存开销
    &#34;&#34;&#34;
    
    # non_zero_vals = img[np.nonzero(img)]
    non_zero_vals = img[img &gt; 0]

    # only threshold if channel isn&#39;t blank
    if len(non_zero_vals) &gt; 0:
        img_max = np.percentile(non_zero_vals, percentile, overwrite_input=True)

        # threshold values down to max
        threshold_mask = img &gt; img_max
        img[threshold_mask] = img_max

    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_resize"><code class="name flex">
<span>def <span class="ident">f_resize</span></span>(<span>img, shape=(1024, 2048), mode='NEAREST')</span>
</code></dt>
<dd>
<div class="desc"><p>resize img with pillow</p>
<p>:param img: (CHANGE) np.array
:param shape: tuple
:param mode: An optional resampling filter. This can be one of Resampling.NEAREST,
Resampling.BOX, Resampling.BILINEAR, Resampling.HAMMING, Resampling.BICUBIC or Resampling.LANCZOS.
If the image has mode “1” or “P”, it is always set to Resampling.NEAREST.
If the image mode specifies a number of bits, such as “I;16”, then the default filter is Resampling.NEAREST.
Otherwise, the default filter is Resampling.BICUBIC
:return:np.array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_resize(img, shape=(1024, 2048), mode=&#34;NEAREST&#34;):
    &#34;&#34;&#34;
    resize img with pillow

    :param img: (CHANGE) np.array
    :param shape: tuple
    :param mode: An optional resampling filter. This can be one of Resampling.NEAREST,
     Resampling.BOX, Resampling.BILINEAR, Resampling.HAMMING, Resampling.BICUBIC or Resampling.LANCZOS.
     If the image has mode “1” or “P”, it is always set to Resampling.NEAREST.
     If the image mode specifies a number of bits, such as “I;16”, then the default filter is Resampling.NEAREST.
     Otherwise, the default filter is Resampling.BICUBIC
    :return:np.array
    &#34;&#34;&#34;
    imode = Image.NEAREST
    if mode == &#34;BILINEAR&#34;:
        imode = Image.BILINEAR
    elif mode == &#34;BICUBIC&#34;:
        imode = Image.BICUBIC
    elif mode == &#34;LANCZOS&#34;:
        imode = Image.LANCZOS
    elif mode == &#34;HAMMING&#34;:
        imode = Image.HAMMING
    elif mode == &#34;BOX&#34;:
        imode = Image.BOX
    if img.dtype != &#39;uint8&#39;:
        imode = Image.NEAREST
    img = Image.fromarray(img)
    img = img.resize((shape[1], shape[0]), resample=imode)
    img = np.array(img).astype(np.uint8)
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.f_rgb2gray"><code class="name flex">
<span>def <span class="ident">f_rgb2gray</span></span>(<span>img, need_not=False)</span>
</code></dt>
<dd>
<div class="desc"><p>rgb2gray</p>
<p>:param img: (CHANGE) np.array
:param need_not: if need bitwise_not
:return: np.array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def f_rgb2gray(img, need_not=False):
    &#34;&#34;&#34;
    rgb2gray

    :param img: (CHANGE) np.array
    :param need_not: if need bitwise_not
    :return: np.array
    &#34;&#34;&#34;
    if img.ndim == 3:
        if img.shape[0] == 3 and img.shape[1] &gt; 3 and img.shape[2] &gt; 3:
            img = img.transpose(1, 2, 0)
        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        if need_not:
            img = cv2.bitwise_not(img)
    return img</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.he_enhance"><code class="name flex">
<span>def <span class="ident">he_enhance</span></span>(<span>img_obj)</span>
</code></dt>
<dd>
<div class="desc"><p>add by @limin on 2023/05/15</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def he_enhance(img_obj):
    &#34;&#34;&#34;
    add by @limin on 2023/05/15

    &#34;&#34;&#34;
    arr = img_obj.image
    if arr.ndim == 3:
        arr = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)  # todo: rgb or bgr
    if arr.dtype == &#39;uint16&#39;:
        arr = cv2.normalize(arr, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    MAX_RANGE = np.power(2, 8)
    arr_invert = (MAX_RANGE - arr).astype(np.uint8)
    arr_invert = cv2.equalizeHist(arr_invert)
    bgr_arr = f_gray2bgr(arr_invert)  # 3d array in bgr format
    return bgr_arr</code></pre>
</details>
</dd>
<dt id="cellbin.image.augmentation.rescale_intensity_v2"><code class="name flex">
<span>def <span class="ident">rescale_intensity_v2</span></span>(<span>img, out_range)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(parallel=True)
def rescale_intensity_v2(img, out_range):
    imin = np.min(img)
    imax = np.max(img)
    _, omax = out_range

    for i in prange(img.shape[0]):
        for j in range(img.shape[1]):
            img[i][j] = ((img[i][j]-imin)/(imax-imin))*omax
    return img</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cellbin.image" href="index.html">cellbin.image</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cellbin.image.augmentation.dapi_enhance" href="#cellbin.image.augmentation.dapi_enhance">dapi_enhance</a></code></li>
<li><code><a title="cellbin.image.augmentation.encode" href="#cellbin.image.augmentation.encode">encode</a></code></li>
<li><code><a title="cellbin.image.augmentation.enhance" href="#cellbin.image.augmentation.enhance">enhance</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_equalize_adapthist" href="#cellbin.image.augmentation.f_equalize_adapthist">f_equalize_adapthist</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_gray2bgr" href="#cellbin.image.augmentation.f_gray2bgr">f_gray2bgr</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_histogram_normalization" href="#cellbin.image.augmentation.f_histogram_normalization">f_histogram_normalization</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_ij_16_to_8" href="#cellbin.image.augmentation.f_ij_16_to_8">f_ij_16_to_8</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_ij_16_to_8_v2" href="#cellbin.image.augmentation.f_ij_16_to_8_v2">f_ij_16_to_8_v2</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_ij_auto_contrast" href="#cellbin.image.augmentation.f_ij_auto_contrast">f_ij_auto_contrast</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_padding" href="#cellbin.image.augmentation.f_padding">f_padding</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_percentile_threshold" href="#cellbin.image.augmentation.f_percentile_threshold">f_percentile_threshold</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_resize" href="#cellbin.image.augmentation.f_resize">f_resize</a></code></li>
<li><code><a title="cellbin.image.augmentation.f_rgb2gray" href="#cellbin.image.augmentation.f_rgb2gray">f_rgb2gray</a></code></li>
<li><code><a title="cellbin.image.augmentation.he_enhance" href="#cellbin.image.augmentation.he_enhance">he_enhance</a></code></li>
<li><code><a title="cellbin.image.augmentation.rescale_intensity_v2" href="#cellbin.image.augmentation.rescale_intensity_v2">rescale_intensity_v2</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>